---
title: prometheus监控Linux主机
date: 2020-02-23
sidebar: 'auto'
categories:
- prometheus
tags:
- Linux
publish: true
---

## node exporter简介

prometheus主要负责数据的收集、查询和存储。例如Linux主机的cpu使用率，内存使用率等数据，需要使用node exporter这个工具。prometheus周期性收集node exporter的数据。


## node exporter部署

下载node exporter工具，并解压

```bash
cd /usr/local/
https://github.com/prometheus/node_exporter/releases/download/v0.18.1/node_exporter-0.18.1.linux-amd64.tar.gz
tar -xzf node_exporter-0.18.1.linux-amd64.tar.gz
cd node_exporter
```
这里我们使用supervisor作为进程管理工具，可以方便管理进程得到启动、停止和重启。

输出默认的supervisor的配置文件

```bash
mkdir etc
cd etc
echo_supervisord_conf > supervisord.conf
```

添加node exporter配置信息

```ini
[program:node_exporter]
; 启动进程的命令
command=/usr/local/node_exporter/node_exporter
; 进程的名称
process_name=node_exporter
; 进程数量
numprocs=1             
; 工作目录
directory=/usr/local/node_exporter/
;自动启动
autostart=true     
; 运行用户        
user=root               
```

启动supervisor服务

```bash
supervisord -c etc/supervisord.con
```
查看端口，`:9100`端口已经监听了

```bash
netstat -tnlp|grep node_exporter
tcp6       0      0 :::9100                 :::*                    LISTEN      94865/node_exporter
```

用curl命令访问，可以看到监控的数据

```bash
curl http://127.0.0.1:9100
```

![测试访问](https://img.array.fun/img/2020/02/24/e4qt0ozbgmjb8aw.webp)

## 配置Prometheus

在Prometheus配置文件加上

```ini
# A scrape configuration containing exactly one endpoint to scrape:
# Here it's Prometheus itself.
scrape_configs:
  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
  - job_name: 'prometheus'

    # metrics_path defaults to '/metrics'
    # scheme defaults to 'http'.

    static_configs:
            - targets: ['192.168.3.3:9090']

  - job_name: 'linux'
    static_configs:
            - targets: ['192.168.3.3:9100']
```

这样,Prometheus就能pull到 Linux主机监控数据了。

## InfluxDB查看查询数据

Prometheus也会把采集到的数据存储到InfluxDB中。可以到influxDB中查看采集到数据

**使用InfluxQL查询数据，最好指定查询数据的条数**

![存储数据](https://img.array.fun/img/2020/02/24/9dq1k6226dt5y2q.webp)
